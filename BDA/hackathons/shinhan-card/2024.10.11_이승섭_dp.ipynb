{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "!pip install xgboost catboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_data_summed=  pd.read_csv('card_data_summed.csv')\n",
    "card_data_other = pd.read_csv('card_data_other.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train test validation split\n",
    "def train_test_val_split(data, train_size=0.8, test_size=0.1, val_size=0.1):\n",
    "    # Split the data\n",
    "    train, test = train_test_split(data, test_size=1-train_size, random_state=42)\n",
    "    test, val = train_test_split(test, test_size=val_size/(test_size+val_size), random_state=42)\n",
    "    return train, test, val\n",
    "\n",
    "\n",
    "# Define features and targets\n",
    "X = card_data_summed[['pk1', 'pk2', 'pk3', 'pk4', 'pk5']]\n",
    "y = card_data_summed[['ca', 'cb', 'cc', 'cd', 'ce', 'cf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, X_val = train_test_val_split(X)\n",
    "y_train, y_test, y_val = train_test_val_split(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost Regressor model\n",
    "def create_xgb_model(params):\n",
    "    model = XGBRegressor(**params)\n",
    "    multi_output_model = MultiOutputRegressor(model)\n",
    "    multi_output_model.fit(X_train, y_train)\n",
    "    return multi_output_model\n",
    "\n",
    "# Define CatBoost Regressor model\n",
    "def create_cb_model(params):\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    return model\n",
    "\n",
    "# Define multi-target evaluation function\n",
    "def evaluate_multi_target(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = root_mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate XGBoost model\n",
    "xgb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'objective': 'reg:squarederror'  # Standard regression objective\n",
    "}\n",
    "\n",
    "xgb_trained_model = create_xgb_model(xgb_params)\n",
    "xgb_mae, xgb_rmse, xgb_r2 = evaluate_multi_target(xgb_trained_model, X_val, y_val)\n",
    "print('XGBoost MAE:', xgb_mae)\n",
    "print('XGBoost RMSE:', xgb_rmse)\n",
    "print('XGBoost R²:', xgb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate CatBoost model\n",
    "cb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'loss_function': 'MultiRMSE',  # Suitable for multi-target regression\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "cb_trained_model = create_cb_model(cb_params)\n",
    "cb_mae, cb_rmse, cb_r2 = evaluate_multi_target(cb_trained_model, X_val, y_val)\n",
    "print('CatBoost MAE:', cb_mae)\n",
    "print('CatBoost RMSE:', cb_rmse)\n",
    "print('CatBoost R²:', cb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "models = ['XGBoost', 'CatBoost']\n",
    "mae = [xgb_mae, cb_mae]\n",
    "rmse = [xgb_rmse, cb_rmse]\n",
    "r2 = [xgb_r2, cb_r2]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].bar(models, mae, color=['blue', 'green'])\n",
    "ax[0].set_title('Mean Absolute Error')\n",
    "ax[1].bar(models, rmse, color=['blue', 'green'])\n",
    "ax[1].set_title('Root Mean Squared Error')\n",
    "ax[2].bar(models, r2, color=['blue', 'green'])\n",
    "ax[2].set_title('R2 Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for XGBoost\n",
    "def objective_xgb(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize XGBoost hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - trial: Optuna trial object.\n",
    "\n",
    "    Returns:\n",
    "    - mae (float): Mean Absolute Error to minimize.\n",
    "    \"\"\"\n",
    "    # Define the hyperparameters to optimize\n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0  # Silent mode\n",
    "    }\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_xgb_model(xgb_params)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae, _, _ = evaluate_multi_target(model, X_val, y_val)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "\n",
    "\n",
    "# Create an Optuna study for XGBoost\n",
    "study_xgb = optuna.create_study(direction='minimize', study_name='XGBoost Optimization')\n",
    "\n",
    "# Optimize the objective function\n",
    "study_xgb.optimize(objective_xgb, n_trials=100, timeout=600)  # Adjust n_trials and timeout as needed\n",
    "\n",
    "# Get the best hyperparameters\n",
    "xgb_best_params = study_xgb.best_params\n",
    "xgb_best_params.update({'objective': 'reg:squarederror', 'random_state': 42, 'verbosity': 0})\n",
    "\n",
    "print(\"Best Hyperparameters for XGBoost:\")\n",
    "print(xgb_best_params)\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 8: Train and Evaluate XGBoost with Best Hyperparameters\n",
    "# -----------------------------\n",
    "# Train the best XGBoost model\n",
    "xgb_best_model = create_xgb_model(xgb_best_params)\n",
    "\n",
    "# Evaluate the best XGBoost model\n",
    "xgb_best_mae, xgb_best_rmse, xgb_best_r2 = evaluate_multi_target(xgb_best_model, X_val, y_val)\n",
    "print('XGBoost Best MAE:', xgb_best_mae)\n",
    "print('XGBoost Best RMSE:', xgb_best_rmse)\n",
    "print('XGBoost Best R²:', xgb_best_r2)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for CatBoost\n",
    "def objective_cb(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize CatBoost hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - trial: Optuna trial object.\n",
    "\n",
    "    Returns:\n",
    "    - mae (float): Mean Absolute Error to minimize.\n",
    "    \"\"\"\n",
    "    # Define the hyperparameters to optimize\n",
    "    cb_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'loss_function': 'MultiRMSE',\n",
    "        'random_state': 42,\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_cb_model(cb_params)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    mae, _, _ = evaluate_multi_target(model, X_val, y_val)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "\n",
    "\n",
    "# Create an Optuna study for CatBoost\n",
    "study_cb = optuna.create_study(direction='minimize', study_name='CatBoost Optimization')\n",
    "\n",
    "# Optimize the objective function\n",
    "study_cb.optimize(objective_cb, n_trials=100, timeout=600)  # Adjust n_trials and timeout as needed\n",
    "\n",
    "# Get the best hyperparameters\n",
    "cb_best_params = study_cb.best_params\n",
    "cb_best_params.update({'loss_function': 'MultiRMSE', 'random_state': 42, 'verbose': False})\n",
    "\n",
    "print(\"Best Hyperparameters for CatBoost:\")\n",
    "print(cb_best_params)\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 10: Train and Evaluate CatBoost with Best Hyperparameters\n",
    "# -----------------------------\n",
    "# Train the best CatBoost model\n",
    "cb_best_model = create_cb_model(cb_best_params)\n",
    "\n",
    "# Evaluate the best CatBoost model\n",
    "cb_best_mae, cb_best_rmse, cb_best_r2 = evaluate_multi_target(cb_best_model, X_val, y_val)\n",
    "print('CatBoost Best MAE:', cb_best_mae)\n",
    "print('CatBoost Best RMSE:', cb_best_rmse)\n",
    "print('CatBoost Best R²:', cb_best_r2)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "models = ['XGBoost', 'CatBoost']\n",
    "mae = [xgb_best_mae, cb_best_mae]\n",
    "rmse = [xgb_best_rmse, cb_best_rmse]\n",
    "r2 = [xgb_best_r2, cb_best_r2]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Mean Absolute Error\n",
    "ax[0].bar(models, mae, color=['skyblue', 'lightgreen'])\n",
    "ax[0].set_title('Mean Absolute Error')\n",
    "ax[0].set_ylabel('MAE')\n",
    "\n",
    "# Root Mean Squared Error\n",
    "ax[1].bar(models, rmse, color=['skyblue', 'lightgreen'])\n",
    "ax[1].set_title('Root Mean Squared Error')\n",
    "ax[1].set_ylabel('RMSE')\n",
    "\n",
    "# R² Score\n",
    "ax[2].bar(models, r2, color=['skyblue', 'lightgreen'])\n",
    "ax[2].set_title('R² Score')\n",
    "ax[2].set_ylabel('R²')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
