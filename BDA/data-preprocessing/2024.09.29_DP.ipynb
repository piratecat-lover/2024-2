{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDA학회 데이터 분석 전처리 적용반 3주차 복습과제\n",
    "\n",
    "제출자 성명: 이승섭89\n",
    "\n",
    "3주차 코드를 재해석합니다.\n",
    "\n",
    "Python 3.10.14 버전을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.feature_selection을 이용하여 분석\n",
    "#### VarianceThreshold()\n",
    "- Select features according to variance.\n",
    "    - Remove features with low variance $\\to$ less importance in model.\n",
    "    - Set threshold to remove features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data X\n",
    "X = [[0,2,0,3],\n",
    "     [0,1,2,3],\n",
    "     [0,1,1,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold as 0.2\n",
    "selector = VarianceThreshold(threshold=0.2)\n",
    "X_high_variance = selector.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical Definition of Variance\n",
    "- Calculates how far data point is from mean.\n",
    "- If data is virtually equivalent to mean, low variance.\n",
    "    - Feature values are nearly constant and invariant, with very high correlation.\n",
    "    - One feature has almost constant values $\\to$ does not help predict target variable.\n",
    "        - Because examining feature gives no information on target variable.\n",
    "        - Fails to add information or even diminishes model predictive performance.\n",
    "        - May lead to overfitting.\n",
    "- If datapoint is far from mean, variance is very high.\n",
    "    - Doesn't mean high-variance features are important.\n",
    "    - Maybe high priority, but should be considered with domain-specific knowledge.\n",
    "- Threshold\n",
    "    - Variances are normally 0.\n",
    "    - 0.1~0.5: Usually acceptable, may differ according to domain.\n",
    "        - Depends on ratio.\n",
    "        - Search based on actual feature variances.\n",
    "        - Test and iterate to evaluate performance of threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\Chi^{2}$ Test\n",
    "- High $\\Chi^{2}$ value: Feature is strongly correlated to target variable.\n",
    "- Fundamentals of Chi-squared:\n",
    "    - Calculates difference between expected values and observed values.\n",
    "    - Expected values assume independent features and variables.\n",
    "    - High Chi-squared value: Difference between expected and observed value is large.\n",
    "        - Feature and variable are highly correlated.\n",
    "        - Feature influences variable more than what is expected.\n",
    "        - Feature with high Chi-squared value is deemed as an indicating feature with high predictive power.\n",
    "    - Categorical/Continuous Data\n",
    "        - Chi-squared works on categorical data, and continuous data must be converted to categorical data first.\n",
    "    - p-value (유의확률) is used as threshold (p < 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy dataset\n",
    "\n",
    "X = np.array([[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9],\n",
    "              [10,11,12]])\n",
    "y = np.array([0,1,0,1]) # Target values (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 2 features\n",
    "selector = SelectKBest(chi2, k=2)\n",
    "X_new = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset and fill missing values\n",
    "tt = sns.load_dataset('titanic')\n",
    "tt['age'] = tt['age'].fillna(tt['age'].median())\n",
    "tt['embark_town'] = tt['embark_town'].fillna(tt['embark_town'].mode()[0])\n",
    "tt['fare'] = tt['fare'].fillna(tt['fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and label\n",
    "X = tt[['pclass', 'sex', 'age', 'fare', 'embark_town']]\n",
    "y = tt['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize continuous variables with qcut ratio\n",
    "\n",
    "X.loc[:, 'age_binned'] = pd.qcut(tt['age'], q=4, labels=False)\n",
    "X.loc[:, 'fare_binned'] = pd.qcut(tt['fare'], q=4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture categorical variables with one-hot encoding\n",
    "X = X.drop(columns=['age', 'fare'])\n",
    "onehot_encoder = OneHotEncoder(sparse_output = False, drop = 'first')\n",
    "\n",
    "X_encoded = onehot_encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select with chi2\n",
    "\n",
    "chi_selector = SelectKBest(chi2, k='all')\n",
    "X_selected_all = chi_selector.fit_transform(X_encoded, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate chi2 scores\n",
    "chi_scores = pd.DataFrame({\n",
    "    'Feature': onehot_encoder.get_feature_names_out(X.columns),\n",
    "    'Score': chi_selector.scores_}).sort_values(by='Score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize chi2 scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(chi_scores['Features'], chi_scores['Score'], color='lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use top 2 features\n",
    "\n",
    "chi_selector_2 = SelectKBest(chi2, k=2)\n",
    "X_selected_2 = chi_selector_2.fit_transform(X_encoded, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate chi2 scores\n",
    "selected_indices = chi_selector_2.get_support(indices=True)\n",
    "selected_features = onehot_encoder.get_feature_names_out(X.columns)[selected_indices]\n",
    "chi_scores_2 = chi_selector_2.scores_[selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize chi2 scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(selected_features, chi_scores_2, color='skyblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필수과제 1:\n",
    "안한 예시 코드 (Variance Threshold)로 Titanic Data Feature Selection하기.\n",
    "임계값 기준을 몇으로 했는지? 그 기준의 이유와 어떤 식으로 찾았는지?\n",
    "어떤 feature가 선택이 되었나?\n",
    "\n",
    "## 필수과제 2:\n",
    "주어진 큰 데이터에서 그 데이터를 feature selection해서 어떤 feature만 추출할 건지, 그리고 그 이유.\n",
    "코드 + 주석 설명, 선택된 feature 설명하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 수업\n",
    "Chi-squared 말고도 ANOVA, MANOVA 등의 방법도 있다. \n",
    "Mutual information을 가지고 해도 된다. 기본적으로 상호정보량은 살펴볼 예정.\n",
    "논문에서도 feature selection 고민하는데, 통계적으로도 많이 하고 있다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-24-windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
