{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Movie Success Metrics Using a Transformer Model\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import transformer components\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets from the 'raw-data' folder\n",
    "credits = pd.read_csv('./raw-data/credits.csv')\n",
    "keywords = pd.read_csv('./raw-data/keywords.csv')\n",
    "movies_metadata = pd.read_csv('./raw-data/movies_metadata.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_column(df, column_name):\n",
    "    \"\"\"Safely parse JSON-like strings in a DataFrame column.\"\"\"\n",
    "    def parse_json(x):\n",
    "        if pd.isna(x):\n",
    "            return []\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    df[column_name] = df[column_name].apply(parse_json)\n",
    "    return df\n",
    "\n",
    "# Parse columns\n",
    "credits = parse_json_column(credits, 'cast')\n",
    "credits = parse_json_column(credits, 'crew')\n",
    "keywords = parse_json_column(keywords, 'keywords')\n",
    "\n",
    "json_columns = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'belongs_to_collection']\n",
    "for column in json_columns:\n",
    "    movies_metadata = parse_json_column(movies_metadata, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract main actors (top 3 billed actors)\n",
    "def get_top_actors(cast_list, n=3):\n",
    "    if isinstance(cast_list, list):\n",
    "        cast_list = sorted(cast_list, key=lambda x: x.get('order', 999))\n",
    "        actors = [member.get('name') for member in cast_list[:n] if member.get('name')]\n",
    "        return actors\n",
    "    return []\n",
    "\n",
    "credits['main_actors'] = credits['cast'].apply(get_top_actors)\n",
    "\n",
    "# Extract director\n",
    "def get_director(crew_list):\n",
    "    if isinstance(crew_list, list):\n",
    "        for member in crew_list:\n",
    "            if member.get('job') == 'Director':\n",
    "                return member.get('name')\n",
    "    return np.nan\n",
    "\n",
    "credits['director'] = credits['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(keywords_list):\n",
    "    return [kw.get('name') for kw in keywords_list if kw.get('name')]\n",
    "\n",
    "keywords['keyword_list'] = keywords['keywords'].apply(get_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop weird values in movies_metadata['production_countries']\n",
    "\n",
    "movies_metadata = movies_metadata[movies_metadata['production_countries'].apply(lambda x: isinstance(x, list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract production countries\n",
    "def get_production_countries(production_countries_list):\n",
    "    return [country.get('iso_3166_1') for country in production_countries_list if country.get('iso_3166_1')]\n",
    "\n",
    "movies_metadata['production_countries_list'] = movies_metadata['production_countries'].apply(get_production_countries)\n",
    "\n",
    "# Extract original language\n",
    "movies_metadata['original_language'] = movies_metadata['original_language'].fillna('Unknown')\n",
    "\n",
    "# Determine if movie is part of a collection\n",
    "def has_collection(collection):\n",
    "    return 1 if isinstance(collection, dict) else 0\n",
    "\n",
    "movies_metadata['has_collection'] = movies_metadata['belongs_to_collection'].apply(has_collection)\n",
    "\n",
    "# Convert release_date to datetime\n",
    "movies_metadata['release_date'] = pd.to_datetime(movies_metadata['release_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'id' columns are numeric\n",
    "movies_metadata['id'] = pd.to_numeric(movies_metadata['id'], errors='coerce')\n",
    "credits['id'] = pd.to_numeric(credits['id'], errors='coerce')\n",
    "keywords['id'] = pd.to_numeric(keywords['id'], errors='coerce')\n",
    "\n",
    "# Merge datasets\n",
    "df = movies_metadata.merge(credits[['id', 'main_actors', 'director']], on='id', how='left')\n",
    "df = df.merge(keywords[['id', 'keyword_list']], on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing release dates\n",
    "df = df.dropna(subset=['release_date'])\n",
    "\n",
    "# Fill missing lists with empty lists\n",
    "list_columns = ['main_actors', 'keyword_list', 'production_countries_list']\n",
    "for col in list_columns:\n",
    "    df[col] = df[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Fill missing director with 'Unknown'\n",
    "df['director'] = df['director'].fillna('Unknown')\n",
    "\n",
    "# Fill missing 'has_collection' with 0\n",
    "df['has_collection'] = df['has_collection'].fillna(0)\n",
    "\n",
    "# Convert budget and revenue to numeric\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce').fillna(0)\n",
    "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce').fillna(0)\n",
    "df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid division by zero\n",
    "df['budget'] = df['budget'].replace(0, np.nan)\n",
    "df['rev_budget_ratio'] = df['revenue'] / df['budget']\n",
    "df['rev_budget_ratio'] = df['rev_budget_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "df['budget'] = df['budget'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variables\n",
    "df['rating'] = pd.to_numeric(df['vote_average'], errors='coerce').fillna(0)\n",
    "df['popularity'] = df['popularity'].fillna(0)\n",
    "\n",
    "# Targets: revenue, rev_budget_ratio, rating, popularity\n",
    "targets = ['revenue', 'rev_budget_ratio', 'rating', 'popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_features(row):\n",
    "    features = []\n",
    "    \n",
    "    # Handle main_actors\n",
    "    actors = row['main_actors']\n",
    "    if isinstance(actors, list):\n",
    "        features.extend([str(actor) for actor in actors if actor])\n",
    "    elif pd.notnull(actors):\n",
    "        features.append(str(actors))\n",
    "    \n",
    "    # Handle director\n",
    "    director = row['director']\n",
    "    if pd.notnull(director):\n",
    "        features.append(str(director))\n",
    "    else:\n",
    "        features.append('Unknown')\n",
    "    \n",
    "    # Handle keyword_list\n",
    "    keywords = row['keyword_list']\n",
    "    if isinstance(keywords, list):\n",
    "        features.extend([str(keyword) for keyword in keywords if keyword])\n",
    "    elif pd.notnull(keywords):\n",
    "        features.append(str(keywords))\n",
    "    \n",
    "    # Handle production_countries_list\n",
    "    countries = row['production_countries_list']\n",
    "    if isinstance(countries, list):\n",
    "        features.extend([str(country) for country in countries if country])\n",
    "    elif pd.notnull(countries):\n",
    "        features.append(str(countries))\n",
    "    \n",
    "    # Handle original_language\n",
    "    language = row['original_language']\n",
    "    if pd.notnull(language):\n",
    "        features.append(str(language))\n",
    "    else:\n",
    "        features.append('Unknown')\n",
    "    \n",
    "    # Handle has_collection\n",
    "    has_collection = row['has_collection']\n",
    "    if has_collection == 1:\n",
    "        features.append('Collection')\n",
    "    else:\n",
    "        features.append('No Collection')\n",
    "    \n",
    "    # Combine features into a single string\n",
    "    return ' '.join(features)\n",
    "\n",
    "df['text_input'] = df.apply(combine_text_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text inputs\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "df['tokenized'] = df['text_input'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, df, targets):\n",
    "        self.inputs = df['tokenized'].tolist()\n",
    "        self.targets = df[targets].values.astype(float)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.float)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.inputs[idx]['input_ids'].squeeze()\n",
    "        attention_mask = self.inputs[idx]['attention_mask'].squeeze()\n",
    "        targets = self.targets[idx]\n",
    "        return input_ids, attention_mask, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Reset indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8  # Reduce this number\n",
    "\n",
    "train_dataset = MovieDataset(train_df, targets)\n",
    "test_dataset = MovieDataset(test_df, targets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieTransformerModel(nn.Module):\n",
    "    def __init__(self, num_targets):\n",
    "        super(MovieTransformerModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_targets)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        # Use [CLS] token representation\n",
    "        cls_output = outputs[1]\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        output = self.fc(cls_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieTransformerModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_targets = len(targets)\n",
    "\n",
    "model = MovieTransformerModel(num_targets)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce 940MX\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA version: 12.4\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, target)\n\u001b[0;32m     14\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 15\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     19\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\Max-PC\\.conda\\envs\\bir_env\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Max-PC\\.conda\\envs\\bir_env\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Max-PC\\.conda\\envs\\bir_env\\Lib\\site-packages\\torch\\optim\\adamw.py:199\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Max-PC\\.conda\\envs\\bir_env\\Lib\\site-packages\\torch\\optim\\optimizer.py:426\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m is_compiling()\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built()\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[0;32m    425\u001b[0m     ):\n\u001b[1;32m--> 426\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    429\u001b[0m             group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups\n\u001b[0;32m    430\u001b[0m         ):\n\u001b[0;32m    431\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    432\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    434\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but param_groups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m capturable is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m             )\n",
      "File \u001b[1;32mc:\\Users\\Max-PC\\.conda\\envs\\bir_env\\Lib\\site-packages\\torch\\cuda\\graphs.py:29\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_current_stream_capturing\u001b[39m():\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for input_ids, attention_mask, target in train_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, target in test_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f'Test Loss: {avg_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
